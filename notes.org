* Thompson et al, 2011

[[https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018093][Link to the paper]] This paper is a benchmark study of multiple sequence alignment
methods. Modern methods are pretty good, but face some challenges: (1) locally
conserved regions are less well aligned, (2) motifs in natively disordered
regions are often misaligned, and (3) the badly predicted or fragmentary protien
sequences in many of today's databases lead to significant number of alignment
errors. Novel approaches will be required to deal with the most difficult
regions.

** Introduction

*** Definitions 

MSA obviously.

BAliBASE -- this is an alignment benchmark suite containing multiple sequence
alignments organized into 9 reference sets representing specific MSA problems.
[Q: what does alignment benchmark suit mean?] The different reference sets
represent specific problems for MSA problems. These include (1) small numbers of
sequences, (2) unequal phylogenetic distributions, (3) large N/C-terminal
extensions or internal insertions, (4) repeats, inverted domains and
transmembrane regions.

Specific features are known as *specificity determining positions* (SPDs) that
modulate a protien's function in a given context.

The most popular alignment algorithms traditionally have been *progressive
alignment procedures* which exploits the fact that progressive alignments are
evolutionarily related. An MSA is built up gradually using a series of pairwise
alignments, following the branching order in a phylogenetic tree. [Q: do we need
a phylogenetic tree to do this?]

A *global MSA algorithm* attempts to align the full length sequences one end to
the other. Often we start with a global alignment and then focus on important
regions. A *local algorithm* attempts to identify subsequences sharing high
similarity. Then the unreliable or low-similarity regions are either excluded or
differentiated (eg by the use of upper/lower case letters).

Gold standard benchmarks indicate that no existing progressive algorithm is
capable of providing accurate alignments for all test cases. As a result,
iterative algorithms have been developed, e.g. Hidden Markov Models and Genetic
Algorithms. These are good for highly conserved regions, but bad for distantly
related sequences.

Challenges: (1) Scalability is a big challenge because we can now make MSAs with
hundreds of organisms; (2) small number of model organisms in public databases;
(3) protein families represented in today's databases are complicated, and (4)
new sequences are mostly predicted by automatic methods and thus contain a large
number of sequence errors [Q: this has something to do about gene sequence
prediction? See bottom of p2]; (5) we now have sequences with billions of bases
produced from read lengths as short as 35-45 nucleotides, resulting in
fragmentary protein sequences. In short, the data is big and noisy.

*** Purpose of this paper

The purpose is to apply a new protein sequence alignment benchmark designed to
give a comprehensive account of the performance of today's most popular MSA
programs. This was motivated by two observations: (1) most of the existing MSA
benchmarks have focused on the patterns conserved in hte majority of the
sequences and not enough attention has been paid to the less-frequent patterns,
or SDPs which might indicate subfamily- or context-specific functions; (2)
current MSA programs for protein sequences generally model globular domain
structure and evolution. [Q: what is "globular domain structure"?] But many
protiens in eukaryotes are unstructured, or contain large unstructured regions
[Q: what does sctructured mean in this context?]

Specifically, the benchmark represents 218 large and complex protein families
and has been incorporated into the BAliBASE benchmark suite. Basically, they
include a new test set, Reference 10, which they add to the pre-existing 9
reference sets in BAliBASE. The new reference set focuses on subamily specific
features, motifs in disordered regions, and the effect of fragmentary or
erroneous sequences on MSA quality. [Q: what does reference set refer to in this
context?]

This is a comparative study to evaulate the most widely-used alignment methods.

[RANDOM QUESTION: Strong selection for gene 1 in the past should speed up
coalescent rate for unrelated gene 2, no? That is, it should have an effect
similar to reducing the effective population size.]



** Results

*** Overall Alignment Quality

Applied 8 alignment programs to each of 218 reference alignments in the
benchmark, resulting in 1744 automatically-constructed MSAs.

Overall quality was measured with Column Score (CS). [what is this? ask methods
team]

Probcons, TCoffee and Mafft did the best. (Scores about 80%). Mafft took only an
hours but the other ones took like 3 days. Kalign took only 3 minutes but had
some loss of accuracy (74%).

Methods that did not combine both local and global approach performed worse.

*** Effect of sequence discrepancies ons alignment quality

Methods did well. But I don't understand what is meant by sequence discrepencies. 

*Discrepencies* are unexpected or discordant extensions, inserions or deletions,
as shown in Figure 2.

*** MSA program evaluation: alignment of locally conserved motifs

Want to see if the MSAs can identify context-specific or locally conserved
motifs.

Various features of blocks in the reference alingments were measured, such as
length of hte block, sequence similarity, frequency the bock is show in the
alignment, and what percent of the block is found in a disordered region.
Alignment quality for each block was measured with a scoring system called BCS.
Programs did not respond in the same way to different block features. For
example, Muscle and TCoffee were affected by the frequency of the blocks.
Probcons and Muscle were less sensitive to similarity of the blocks.

Blocks with significant number of residues in "natively disordered segments" had
low scores with every program. [what does that mean?]

What is a disordered segment?

*** Improving local alignment quality by combining methods

They construct a theoretical top score by choosing for each block the top score
achieved by any of the inference methods considered.

* Di Franco et al. 2019
[[https:bmcecolevol.biomedcentral.com/track/pdf/10.1186/s12862-019-1350-2.pdf][Link to the paper]]. 
** Issue
Molecular evolutionary analysis begins with the construction of multiple
sequence alignments. It is therefore important to limit the propagation of
alignment errors. Potential errors are multiple: alignment errors, as well as
the more ominous "primary errors" which include sequencing errors, assembly
errors. and annotation errors.
** Significance
** Approach
The authors develop an HMM called HmmCleaner, which detects and eliminates
errors in MSAs. They perform two analyses:

  1. They first assess the performance of HmmCleaner using ~700 amino-acid MSAs
     in which primary (i.e. non-alignment) errors were artificially introduced.

  2. Next they compared two "segment-filtering methods", HmmCleaner and PREQUAL,
     with block-filtering software (BMGE and TrimAI). Specifically, they
     compared the impact on evolutionary analysis using vertebrate data.
** Methods
- HmmCleaner has four steps: 
  1. create a profile pHMM based on the MSA
  2. estimate the probability that the pHMM generates each amino acid of a given
     sequence of the MSA (the assumption here is that a primary sequence error
     should have very low probability)
  3. calculate a cumulative similarity score for each sequence
  4. segments with score zero or lower are "low similarity segments"
- Dataset creation:
  1. MSAs of protein-coding genes from prokaryotes. Purpose: to study
     performance of HMMCleaner.
  2. Datasets assembled from animal sequences. Purpose: to study impact on
     evolutionary inferences.
- Simulator:
  - Input: a protein-coding alignment (MSA)
  - Randomly introduces primary sequence errors (e.g. scrambling a segment or
    inserting a scrambled segment, frameshift (i.e. the insertion/deletion of a
    number of sites not divisible by three))
  - Translates all sequences to protiens and realigns them with MAFFT
  - Output: an MSA with errors
  - Then run HmmCleaner on the output MSA. Regions with low similarity scores
    are compared to the locations of the simulated errors to obtain type I and
    type II error probabilities.
- Parameter Optimization
  - HMMCleaner has 4 scoring parameters. HMMCleaner was run on the prokaryotic
    datasets using thousands of combinations of parameters in order to find the
    best values to use.
- Characterization of HmmCleaner performance:
  - Prokaryotic Data
  - HmmCleaner was compared to 4 other filtering methods
- Effect of HmmCleaner on evolutionary inferences
  - Animal MSAs
  - Selection: For each simulation, we test for positive simulation using (1) the original
    MSA (2) the MSA cleaned by the programs, (3) erroneous MSA, and (4) the
    erroneous filtered MSA.
  - Phylogenies: Tested 11 different filtering setups, then used RAxML on each MSA
** Results
In the first analysis, HmmCleaner exhibited >95% sensitivity to primary sequence
errors. HmmmCleaner targets low-similarity segments for removal, rather than whole blocks.

In the second analysis, they find that segment-filtering methods improve
evolutionary inference better than block-filtering, especially with respect to
improving branch length inferences and reducing false positive rate during
detection of positive selection.
** Conclusions
- Reccommend the use of segment-filtering methods for eukaryotic genomic data.
- Primary sequence errors more detrimental than alignment errors (didn't understand why)
- 
** Questions
Does anyone really know how illumina works? Don't they use proprietary methods?
Like... doesn't that preclude replication?
* Ballesteros & Hormiga 2016
[[https://doi.org/10.1093/molbev/msw069][Link to paper]] This paper introduces a phylogenetic orthology method that does
not depend on root placement and does not require explicit assignment of groups.
This method is applied to a small insects dataset. Also apply to RNAseq data
from spiders--to identify and document stable orthologs.

** Issue
A fundamental assumption in phylogenetics is that the loci used to infer
evolutionary relationships are orthologs. Most methods of orthology detection
evaluate orthology using some measurement of similarity. Most methods don't
perform better than BLAST. In addition, orthology detection usually requires
computationally intensive pairwaise comparisons (for distance-based methods) or
tree inference (for phylogeny based methods).

Tree-based orthology detection methods are increasingly popular. But inferred
orthologies may depend on the root of the tree.

There are not enough stable orthology hypotheses, especially for invertabrates.


RNA sequencing (aka "transcriptomics") is increasingly used for phylogenetics.
But while these efforts usually involve some form of orthology and homology
assessment, but since the main goal is to recover the species tree, the
orthology detection results are generally treated as byproducts and are not
saved for future reference.

** Definitions
"Tree-based orthology detection methods" are methods that use the phylogeny of
gene families to infer events of duplication-speciation of the gene copies,

"Stable orthology hypotheses" = a database of identified "ultraconserved
elements" (UCEs) which can be individually accessed and further documented.

** Significance
Not using orthologs can lead to phylogenetic conflict.
** Approach
Introduce UPhO (unrooted phylogenetic orthology), an orthology assessment method
which does not depend on the root in the input gene family trees. Then
 - Test UPhO on a trivial example of vertebrate hemoglobins.
 - Using a small insect dataset, compare the use of UPhO with other methods when
   used in a phylogenomic pipeline.
 - Test UPhO on transcriptomic data using a dataset of 27 spider species. The
   goal was to identify orthologs at "specific hierarchical levels." The spider
   dataset was evaluated under a variety of homology (clustering) methods.

** Methods
UPhO is an orthology assessment tool that is used AFTER homology detection step
AND construction of gene trees.
** Results
A gene family tree is a green trees whose tips reside in the leaves of the
species tree. Not all leaves of the species tree contain tips of the gene tree;
and some leaves may have more.

The method UPhO classifies splits in gene trees by comparing the number of leafs of
the gene tree with the number of species tree leaves that it is contained in. If
these numbers are the same, then the split is thought to be orthologous.
Otherwise it is a "paralogous split" (i.e. assumed to arise from a duplication).
If the tips of the gene tree are all contained in a single leaf of the species
tree, then the split is called "in-paralogous".

*Vertebrate Hemoglobins:* didn't really understand this.

*Insects Proteomes:* A clustering algorithm identified 2538 clusters (i.e.
potential orthologs) from 1906 alignments. The results were input to UPhO and
PTP (some other method: PhyloTreePruner) and were compared with results from a
dataset called OMA.

UPhO consistently discovered more orthogroups than PTP and OMA.

Astral consistently recovered the species phylogeny regardless of orthology
assessment. [This does not surprise me given our consistency results in the
DLCoal project.]

*Spiders:* BLAST produced 12,000 clusters with at least 5 species. When
accepting in-paralogs, they discovered 3x as many orthologs as PTP. SC datasets
showed heterogenous and conflicted phylogenetic signals. See Figure 6 for a nice
picture of the resulting tree.

** Conclusions
** Questions
What exactly does "tree pruning" mean? 

What is ribosomal DNA? 

"have a restricted set of molecular markers available for phylogenetic
inference" -- what does this mean? Not much DNA?

What does BLAST do? BLAST finds regions of similarity between biological
sequences. It compares sequences to sequence databases and calculates statistica
significance.

What is ancestor-descendant polarity?

What is proteome? All the proteins in a cell

What does it mean for a cluster to be composed of "single copy" (SC) genes?
* Yang 2017
** Problem 3: Fair-balance paradox. The true model is standard normal. We compare
$H_1$ and $H_2$ which are normal mean $\mu$ but with variances bigger or less
than 1, chosen so that their KL divergence from the truth is equidistant
("equally wrong"). Uniform prior over the models (each pr 1/2). P_1 is the
posterior model probabilities.

As n goes to infinity, P_1 congerges to a 2-point distribution at 0 and 1, each
with probability 1/2. When one is closer to the truth, convergence to the
correct model occurs, but the more wrong model can have high posterior for
finite n (eg 99% in 5% of datasets when n=100). This is a "twilight zone" in
which there is high probability of rejecting the true tree.

** Star-Tree Paradox and Bayesian Phylogenetics
3 simple cases of trees with just 3 or 4 species. 

*** Case A: equally right models
T_0 is the star tree with branch length t=0.2 The best-fitting parameter values
are internal branch length 0 and other branch length 0.2. The prior
probabilities on the three binary trees is that they are equally likely. JC
substitution model is used to both generate and analyze the data.

*** Case B: equally wrong models
JC+Gamma model of evolution is used to generate the data. But the data are
analyzed using JC. In this cases the three binary trees are equally wrong
because under each binary tree, the MLE for the branch lengths is t_0 = 0 and
t_1 = 0.164. The KL divergence is positive and equal for each of the binary
trees.

*** Case C: equally wrong and distinct models
Simulation model is JC+Gamma, but analysis model is JC. Molecular clock is not
assumed. We consider unrooted four-leaf trees. For all of the three binary
trees, the best-fitting parameter values are are (internal) t_0=0.01 and
t_i=0.164 for i=1,2,3,4 (pendant edges). The posterior degenerates into a
probability measure that assigns 100$ to exactly one of the binary trees (which
happens to each tree with probability 1/3). This is "type-3 polarized behavior."
This is the most important scenario for real phylogenetic analysis.

*** Discussion

**** High posterior probabilities for phylogenetic trees
This work was motivated by the problem of spuriously high posterior
probabilities for phylogenetic trees. One explanation for this is the failure of
current evolutionary models to accommodate interdependence among sites in the
sequence, which leads to exaggeration of the amount of information in the data.
But consideration of coding/noncoding genes suggesets this might not be the true
cause of the issue.

The problem might be deeper than that. It may be a consequence of the polarized
nature of Bayesian model selection when all models are misspecified. 

**** Bayesian Selection of Opposing Misspecified Models
This paper considered the asymptotic behavior of the Bayesian method as data
size goes to infinity, but in the cases where there are model selection
problems. "Equally right" and "equally wrong" cases were considered.

The authors categorize three different types of asymptotic behavior:

- Type-1: ("sensible") -- the posterior probability converges to a sensible
  value, such as 1/2. Unfortunately, this occurs only when the two models are
  identical or overlapping.
- Type-2: ("volatile") -- the posterior distribution fluctates among datasets
  like a random number, so that some models may have support. This occurs when
  models are equally right or equally wrong but "indistinct". Less of a problem,
  since this occurs only when models are essentially the same interpretation of
  the data. For example, if the truth is a star tree and the posterior gives
  strong support to a random one of three binary trees, all of which have the
  same, very short internal branch length (and hence should be suported as
  evidence of polytomy).
- Type-3: ("polarize") -- the posterior is approximately zero in half the
  datasets and approximately 1 in the other half. This occurs when two models
  are equally wrong and distinct. Most relevant to practical application,
  because all models are wrong. When one model is slightly less wrong, it will
  win with infinite data, but Bayesian inference will be overconfident and
  support the more wrong model with high posterior too often.

Something about "posterior predictive distribution".

Extreme sensitivity fo the assumed model is undesirable. There are two heuristic
approaches to remedy the high posterior model probabilities in the context of
phylogenies:

1. Assing nonzero probabilities to multifurcating trees (e.g. star trees) in the
   prior.
2. Let internal branch length in the binary trees become increasingly smaller in
   the prior when the data size increases.

**** Non-Bayesian Methods
Cox's likelihood-ratio test--which conducts multiple tests with each model used
as the null--can be used to compare nonnested models. Not widely used in
phylogentics for computational reasons (too many trees).

The bootstrap support is the most commonly used method for attaching a measure
of confidence in the maximum-likelihood tree. For this, sites (alignment
columns) are sampled to generate N bootstrap pseudodatasets and then we
calculate the bootstrap support value for a clade (a node on the tree) to be the
the proportion of times (out of N) in which that node is inferred in the ML
tree. A straightforward interpretation of the bootstrap support values for trees
remains elusive.

*** My questions:
I would like to better understand this sentence:

"This application of bootstrap for model comparison appears to have important
differences from the conventional bootstrap for calculating the standard errors
and confidence intervals for a parameter estimate (40); a straightforward inter-
pretation of the bootstrap support values for trees remains elusive (31,
41â€“43)."
